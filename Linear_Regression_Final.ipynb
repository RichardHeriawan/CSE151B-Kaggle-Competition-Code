{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J3VsmcZU4O8I"
   },
   "source": [
    "# 1 - Multilayer Perceptron\n",
    "\n",
    "In this series, we'll be building machine learning models (specifically, neural networks) to perform image classification using PyTorch and Torchvision. \n",
    "\n",
    "In this first notebook, we'll start with one of the most basic neural network architectures, a multilayer perceptron (MLP), also known as a feedforward network. The dataset we'll be using is the famous MNIST dataset, a dataset of 28x28 black and white images consisting of handwritten digits, 0 to 9.\n",
    "\n",
    "We'll process the dataset, build our model, and then train our model. Afterwards, we'll do a short dive into what the model has actually learned.\n",
    "\n",
    "### Data Processing\n",
    "\n",
    "Let's start by importing all the modules we'll need. The main ones we need to import are:\n",
    "- torch for general PyTorch functionality\n",
    "- torch.nn and torch.nn.functional for neural network based functions\n",
    "- torch.optim for our optimizer which will update the parameters of our neural network\n",
    "- torch.utils.data for handling the dataset\n",
    "- torchvision.transforms for data augmentation\n",
    "- torchvision.datasets for loading the dataset\n",
    "- sklearn's metrics for visualizing a confusion matrix\n",
    "- sklearn's decomposition and manifold for visualizing the neural network's representations in two dimensions\n",
    "- matplotlib for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "CHadwpvmREvE"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import decomposition\n",
    "from sklearn import manifold\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import copy\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WFMp16oI4O8N"
   },
   "source": [
    "To ensure we get reproducible results we set the random seed for Python, Numpy and PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNG SEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "rvBiLgLAREvN"
   },
   "outputs": [],
   "source": [
    "SEED = 12345\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, train):\n",
    "        self.train_data = torch.tensor(pd.read_csv(train).astype('float32').values)\n",
    "        self.targets = torch.tensor(pd.read_csv(\"train_targets.csv\").astype('float32').values)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        return self.train_data[idx], self.targets[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yDMpvXwB4O8Q"
   },
   "source": [
    "The first thing we'll do is load our dataset.\n",
    "\n",
    "This will automatically download the training set for the MNIST dataset and save it in a folder called `.data`. It will create the folder if it does not exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "UOIQVy-cREvQ"
   },
   "outputs": [],
   "source": [
    "train_data = CustomDataset(\"train_engineered.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.0000,  0.0000, -0.1845,  0.0000, -0.0361]), tensor([-0.5643]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ayyHLZjg4O8o"
   },
   "source": [
    "We can simply check the `len` of the datasets to see how many examples are within each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "fPo3pfgciRo3",
    "outputId": "ae4c193d-f5a8-491b-89c7-ebf9fd456312"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 1710670\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of training examples: {len(train_data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HDgsLY3k4O87"
   },
   "source": [
    "The MNIST dataset comes with a training and test set, but not a validation set. We want to use a validation set to check how well our model performs on unseen data. Why don't we just use the test data? We should only be measuring our performance over the test set once, after all training is done. We can think of the validation set as a proxy test set we are allowed to look at as much as we want. \n",
    "\n",
    "Furthermore, we create a validation set, taking 10% of the training set. **Note:** the validation set should always be created from the training set. Never take the validation set from the test set. When researchers publish research papers they should be comparing performance across the test set and the only way to ensure this is a fair comparison is for all researchers to use the same test set. If the validation set is taken from the test set, then the test set is not the same as everyone else's and the results cannot be compared against each other.\n",
    "\n",
    "First, we have to define the exact number of examples that we want to be in each split of the training/validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "2QI6JckYREve"
   },
   "outputs": [],
   "source": [
    "VALID_RATIO = 0.95\n",
    "\n",
    "n_train_examples = int(len(train_data) * VALID_RATIO)\n",
    "n_valid_examples = len(train_data) - n_train_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Be4vqf484O9A"
   },
   "source": [
    "Then, we use the `random_split` function to take a random 10% of the training set to use as a validation set. The remaining 90% will stay as the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "6yVJvPZ-RVvI"
   },
   "outputs": [],
   "source": [
    "train_data, valid_data = data.random_split(train_data,\n",
    "                                           [n_train_examples, n_valid_examples])\n",
    "\n",
    "TEST_RATIO = 0.95\n",
    "n_valid_examples = int(len(valid_data) * VALID_RATIO)\n",
    "n_test_examples = len(valid_data) - n_valid_examples\n",
    "valid_data, test_data = data.random_split(valid_data,\n",
    "                                           [n_valid_examples, n_test_examples])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p8DYs4UE4O9E"
   },
   "source": [
    "We can print out the number of examples again to check our splits are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "tBhHj9uaREvi",
    "outputId": "4f5089ea-f796-43be-a9a6-250bcdd009f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 1625136\n",
      "Number of validation examples: 81257\n",
      "Number of testing examples: 4277\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of training examples: {len(train_data)}')\n",
    "print(f'Number of validation examples: {len(valid_data)}')\n",
    "print(f'Number of testing examples: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C7vOeo1a4O9W"
   },
   "source": [
    "Next, we'll define a `DataLoader` for each of the training/validation/test sets. We can iterate over these, and they will yield batches of images and labels which we can use to train our model.\n",
    "\n",
    "We only need to shuffle our training set as it will be used for stochastic gradient descent, and we want each batch to be different between epochs. As we aren't using the validation or test sets to update our model parameters, they do not need to be shuffled.\n",
    "\n",
    "Ideally, we want to use the biggest batch size that we can. The 64 here is relatively small and can be increased if our hardware can handle it.\n",
    "\n",
    "# BATCH SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "sGdKSORpREvr"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1000\n",
    "\n",
    "train_iterator = data.DataLoader(train_data,\n",
    "                                 shuffle=True,\n",
    "                                 batch_size=BATCH_SIZE)\n",
    "\n",
    "valid_iterator = data.DataLoader(valid_data,\n",
    "                                 batch_size=BATCH_SIZE)\n",
    "\n",
    "test_iterator = data.DataLoader(test_data,\n",
    "                                batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  0.0000, -0.2026,  0.0000, -0.0615],\n",
      "        [-0.9405,  0.4279,  0.0970,  0.0000,  0.0501],\n",
      "        [ 0.0000,  0.0000, -0.1676,  0.0000, -0.0358],\n",
      "        ...,\n",
      "        [-0.5037, -1.0143, -0.2026,  0.0000, -0.0040],\n",
      "        [-1.6893,  0.3163,  0.0433,  0.0000,  0.0247],\n",
      "        [ 0.0000,  0.0000,  0.1278,  0.1824, -0.0188]])\n",
      "tensor([[-3.6718e-01],\n",
      "        [-3.4527e-01],\n",
      "        [-1.2622e-01],\n",
      "        [ 2.6809e-01],\n",
      "        [-1.0463e+00],\n",
      "        [-2.1384e-01],\n",
      "        [-6.0814e-01],\n",
      "        [ 2.1739e+00],\n",
      "        [-3.0146e-01],\n",
      "        [-4.5480e-01],\n",
      "        [ 1.4729e+00],\n",
      "        [ 5.2187e-03],\n",
      "        [-4.3290e-01],\n",
      "        [ 7.9383e-01],\n",
      "        [ 2.7125e-02],\n",
      "        [ 8.3764e-01],\n",
      "        [-3.0146e-01],\n",
      "        [ 3.9952e-01],\n",
      "        [-2.7956e-01],\n",
      "        [-3.6718e-01],\n",
      "        [-1.0431e-01],\n",
      "        [ 6.1858e-01],\n",
      "        [-3.2337e-01],\n",
      "        [ 2.0237e-01],\n",
      "        [ 5.3096e-01],\n",
      "        [ 7.0936e-02],\n",
      "        [ 1.3665e-01],\n",
      "        [-1.2622e-01],\n",
      "        [-4.3290e-01],\n",
      "        [-1.0463e+00],\n",
      "        [-3.8909e-01],\n",
      "        [-3.2337e-01],\n",
      "        [-1.0431e-01],\n",
      "        [ 1.7358e+00],\n",
      "        [ 9.9098e-01],\n",
      "        [ 1.8046e-01],\n",
      "        [ 5.2187e-03],\n",
      "        [-1.2622e-01],\n",
      "        [-3.4527e-01],\n",
      "        [-2.3574e-01],\n",
      "        [-4.7671e-01],\n",
      "        [-1.6687e-02],\n",
      "        [-4.7671e-01],\n",
      "        [-1.7003e-01],\n",
      "        [-1.0431e-01],\n",
      "        [ 1.5856e-01],\n",
      "        [-2.5765e-01],\n",
      "        [-3.2337e-01],\n",
      "        [-4.9861e-01],\n",
      "        [-3.4527e-01],\n",
      "        [-1.6687e-02],\n",
      "        [ 1.3415e+00],\n",
      "        [ 6.1858e-01],\n",
      "        [-1.6687e-02],\n",
      "        [ 1.4704e+01],\n",
      "        [-9.1482e-01],\n",
      "        [ 9.4717e-01],\n",
      "        [-6.5195e-01],\n",
      "        [-2.3574e-01],\n",
      "        [ 2.6809e-01],\n",
      "        [-7.6148e-01],\n",
      "        [ 6.4049e-01],\n",
      "        [-7.6148e-01],\n",
      "        [ 3.7762e-01],\n",
      "        [ 4.2143e-01],\n",
      "        [-5.6433e-01],\n",
      "        [ 4.4333e-01],\n",
      "        [ 3.5571e-01],\n",
      "        [-1.2622e-01],\n",
      "        [-5.6433e-01],\n",
      "        [ 1.1475e-01],\n",
      "        [-5.2052e-01],\n",
      "        [ 1.5856e-01],\n",
      "        [ 4.9030e-02],\n",
      "        [-1.9193e-01],\n",
      "        [-3.0146e-01],\n",
      "        [-1.0463e+00],\n",
      "        [ 5.9667e-01],\n",
      "        [ 5.2187e-03],\n",
      "        [-6.5195e-01],\n",
      "        [ 5.0905e-01],\n",
      "        [-4.9861e-01],\n",
      "        [-4.5480e-01],\n",
      "        [-6.0499e-02],\n",
      "        [-6.0814e-01],\n",
      "        [-7.1767e-01],\n",
      "        [-1.4812e-01],\n",
      "        [ 9.2842e-02],\n",
      "        [ 2.7125e-02],\n",
      "        [-2.1384e-01],\n",
      "        [ 2.8999e-01],\n",
      "        [-3.8593e-02],\n",
      "        [-3.8909e-01],\n",
      "        [-1.9193e-01],\n",
      "        [-8.0529e-01],\n",
      "        [-1.0431e-01],\n",
      "        [-6.5195e-01],\n",
      "        [ 1.0786e+00],\n",
      "        [ 2.0237e-01],\n",
      "        [-3.8909e-01],\n",
      "        [-1.0463e+00],\n",
      "        [ 7.7192e-01],\n",
      "        [ 4.4333e-01],\n",
      "        [ 5.0905e-01],\n",
      "        [ 9.6907e-01],\n",
      "        [ 1.5856e-01],\n",
      "        [-4.5480e-01],\n",
      "        [ 5.3096e-01],\n",
      "        [ 4.6524e-01],\n",
      "        [ 1.5856e-01],\n",
      "        [-6.0499e-02],\n",
      "        [ 7.0936e-02],\n",
      "        [ 3.9952e-01],\n",
      "        [-5.4243e-01],\n",
      "        [-6.7386e-01],\n",
      "        [-4.9861e-01],\n",
      "        [-3.6718e-01],\n",
      "        [-8.2720e-01],\n",
      "        [-1.0463e+00],\n",
      "        [-3.4527e-01],\n",
      "        [-4.3290e-01],\n",
      "        [-7.3958e-01],\n",
      "        [ 2.2428e-01],\n",
      "        [-3.4527e-01],\n",
      "        [-5.2052e-01],\n",
      "        [ 4.2143e-01],\n",
      "        [-3.4527e-01],\n",
      "        [-5.6433e-01],\n",
      "        [-2.3574e-01],\n",
      "        [ 1.3543e+01],\n",
      "        [-2.7956e-01],\n",
      "        [-1.0463e+00],\n",
      "        [-8.0529e-01],\n",
      "        [-6.0814e-01],\n",
      "        [-5.4243e-01],\n",
      "        [-2.7956e-01],\n",
      "        [ 2.2428e-01],\n",
      "        [-5.2052e-01],\n",
      "        [-8.2720e-01],\n",
      "        [-5.8624e-01],\n",
      "        [-6.7386e-01],\n",
      "        [-2.1384e-01],\n",
      "        [ 2.8999e-01],\n",
      "        [-1.0463e+00],\n",
      "        [-1.2622e-01],\n",
      "        [-2.5765e-01],\n",
      "        [-2.7956e-01],\n",
      "        [ 2.4618e-01],\n",
      "        [-6.0814e-01],\n",
      "        [ 5.0905e-01],\n",
      "        [-4.5480e-01],\n",
      "        [-6.5195e-01],\n",
      "        [-6.0499e-02],\n",
      "        [ 7.2811e-01],\n",
      "        [-5.8624e-01],\n",
      "        [ 1.9767e+00],\n",
      "        [-7.6148e-01],\n",
      "        [-1.9193e-01],\n",
      "        [-4.9861e-01],\n",
      "        [-9.1482e-01],\n",
      "        [ 4.2143e-01],\n",
      "        [-3.2337e-01],\n",
      "        [ 4.4333e-01],\n",
      "        [-3.8593e-02],\n",
      "        [-2.1384e-01],\n",
      "        [ 9.2842e-02],\n",
      "        [-8.2404e-02],\n",
      "        [ 2.4618e-01],\n",
      "        [-2.5765e-01],\n",
      "        [ 1.8046e-01],\n",
      "        [ 2.6809e-01],\n",
      "        [ 4.9030e-02],\n",
      "        [-1.6687e-02],\n",
      "        [ 2.1520e+00],\n",
      "        [-5.2052e-01],\n",
      "        [ 3.9952e-01],\n",
      "        [ 1.1475e-01],\n",
      "        [-2.1384e-01],\n",
      "        [ 2.0237e-01],\n",
      "        [-6.7386e-01],\n",
      "        [-3.0146e-01],\n",
      "        [-5.2052e-01],\n",
      "        [-3.8909e-01],\n",
      "        [-1.7003e-01],\n",
      "        [ 3.1190e-01],\n",
      "        [ 1.5856e-01],\n",
      "        [-5.6433e-01],\n",
      "        [-8.2404e-02],\n",
      "        [ 1.1881e+00],\n",
      "        [ 1.0567e+00],\n",
      "        [-3.8593e-02],\n",
      "        [ 6.4049e-01],\n",
      "        [-3.8909e-01],\n",
      "        [-7.3958e-01],\n",
      "        [ 1.3665e-01],\n",
      "        [ 6.8430e-01],\n",
      "        [ 9.2842e-02],\n",
      "        [-3.8909e-01],\n",
      "        [-1.7003e-01],\n",
      "        [-3.8593e-02],\n",
      "        [ 2.7125e-02],\n",
      "        [ 7.0620e-01],\n",
      "        [ 1.5386e+00],\n",
      "        [-2.1384e-01],\n",
      "        [-9.1482e-01],\n",
      "        [-2.7956e-01],\n",
      "        [ 5.6131e+00],\n",
      "        [ 5.2187e-03],\n",
      "        [ 2.6809e-01],\n",
      "        [-3.0146e-01],\n",
      "        [-3.8909e-01],\n",
      "        [-4.9861e-01],\n",
      "        [-9.5864e-01],\n",
      "        [-3.8593e-02],\n",
      "        [ 7.0936e-02],\n",
      "        [ 3.9952e-01],\n",
      "        [-1.0463e+00],\n",
      "        [ 2.0237e-01],\n",
      "        [-3.8593e-02],\n",
      "        [-4.1099e-01],\n",
      "        [-1.4812e-01],\n",
      "        [-4.1099e-01],\n",
      "        [-3.8909e-01],\n",
      "        [ 4.9030e-02],\n",
      "        [ 3.5571e-01],\n",
      "        [ 1.8046e-01],\n",
      "        [ 2.2834e+00],\n",
      "        [-3.8593e-02],\n",
      "        [ 1.5856e-01],\n",
      "        [ 2.4587e+00],\n",
      "        [-3.4527e-01],\n",
      "        [ 2.0237e-01],\n",
      "        [ 5.7477e-01],\n",
      "        [ 2.6809e-01],\n",
      "        [ 9.2842e-02],\n",
      "        [-7.1767e-01],\n",
      "        [-3.6718e-01],\n",
      "        [-1.9193e-01],\n",
      "        [ 6.8430e-01],\n",
      "        [-6.0814e-01],\n",
      "        [ 2.6809e-01],\n",
      "        [-1.7003e-01],\n",
      "        [-1.0431e-01],\n",
      "        [-7.3958e-01],\n",
      "        [ 1.1475e-01],\n",
      "        [ 9.0336e-01],\n",
      "        [-3.6718e-01],\n",
      "        [ 3.5571e-01],\n",
      "        [-2.7956e-01],\n",
      "        [-8.2404e-02],\n",
      "        [-3.0146e-01],\n",
      "        [-6.0499e-02],\n",
      "        [-8.2404e-02],\n",
      "        [ 7.0936e-02],\n",
      "        [-1.0431e-01],\n",
      "        [-4.9861e-01],\n",
      "        [ 1.7796e+00],\n",
      "        [ 6.6239e-01],\n",
      "        [-3.6718e-01],\n",
      "        [-4.7671e-01],\n",
      "        [-1.0431e-01],\n",
      "        [-8.2720e-01],\n",
      "        [-1.9193e-01],\n",
      "        [-3.8909e-01],\n",
      "        [-1.0463e+00],\n",
      "        [ 2.7125e-02],\n",
      "        [ 5.2187e-03],\n",
      "        [-1.0463e+00],\n",
      "        [-4.7671e-01],\n",
      "        [-3.6718e-01],\n",
      "        [ 5.9667e-01],\n",
      "        [-3.2337e-01],\n",
      "        [-5.4243e-01],\n",
      "        [ 1.1881e+00],\n",
      "        [-6.5195e-01],\n",
      "        [-4.5480e-01],\n",
      "        [-1.7003e-01],\n",
      "        [ 8.5954e-01],\n",
      "        [-6.0499e-02],\n",
      "        [ 9.9098e-01],\n",
      "        [-5.8624e-01],\n",
      "        [-5.2052e-01],\n",
      "        [-6.3005e-01],\n",
      "        [ 6.4049e-01],\n",
      "        [ 1.8046e-01],\n",
      "        [ 2.2428e-01],\n",
      "        [ 2.4618e-01],\n",
      "        [ 4.6524e-01],\n",
      "        [-1.0431e-01],\n",
      "        [-4.9861e-01],\n",
      "        [-3.6718e-01],\n",
      "        [ 5.9667e-01],\n",
      "        [-5.2052e-01],\n",
      "        [-3.4527e-01],\n",
      "        [-4.7671e-01],\n",
      "        [ 3.3381e-01],\n",
      "        [ 1.8046e-01],\n",
      "        [ 1.0129e+00],\n",
      "        [ 2.7125e-02],\n",
      "        [ 3.9952e-01],\n",
      "        [-6.0814e-01],\n",
      "        [-5.2052e-01],\n",
      "        [ 7.0620e-01],\n",
      "        [ 5.2187e-03],\n",
      "        [-5.2052e-01],\n",
      "        [ 1.4510e+00],\n",
      "        [-8.2404e-02],\n",
      "        [ 1.7139e+00],\n",
      "        [-1.0463e+00],\n",
      "        [-2.1384e-01],\n",
      "        [-2.5765e-01],\n",
      "        [ 2.6809e-01],\n",
      "        [-7.1767e-01],\n",
      "        [ 4.2143e-01],\n",
      "        [ 1.3665e-01],\n",
      "        [-1.7003e-01],\n",
      "        [ 7.9383e-01],\n",
      "        [ 2.6809e-01],\n",
      "        [ 1.4291e+00],\n",
      "        [-1.7003e-01],\n",
      "        [-4.3290e-01],\n",
      "        [-6.7386e-01],\n",
      "        [-1.2622e-01],\n",
      "        [-3.0146e-01],\n",
      "        [-6.7386e-01],\n",
      "        [ 2.6809e-01],\n",
      "        [-1.9193e-01],\n",
      "        [-8.2404e-02],\n",
      "        [-5.2052e-01],\n",
      "        [-2.1384e-01],\n",
      "        [-4.5480e-01],\n",
      "        [-2.1384e-01],\n",
      "        [-5.8624e-01],\n",
      "        [-7.3958e-01],\n",
      "        [-1.4812e-01],\n",
      "        [-1.0244e+00],\n",
      "        [-2.1384e-01],\n",
      "        [-6.3005e-01],\n",
      "        [ 2.7125e-02],\n",
      "        [-6.5195e-01],\n",
      "        [-6.0814e-01],\n",
      "        [ 6.8430e-01],\n",
      "        [-9.3673e-01],\n",
      "        [-7.6148e-01],\n",
      "        [ 3.5571e-01],\n",
      "        [ 3.3381e-01],\n",
      "        [-2.5765e-01],\n",
      "        [-3.8909e-01],\n",
      "        [-8.2404e-02],\n",
      "        [ 2.0237e-01],\n",
      "        [-2.1384e-01],\n",
      "        [-1.9193e-01],\n",
      "        [-1.4812e-01],\n",
      "        [ 2.6809e-01],\n",
      "        [-3.6718e-01],\n",
      "        [-4.9861e-01],\n",
      "        [ 2.4618e-01],\n",
      "        [ 5.5286e-01],\n",
      "        [-2.7956e-01],\n",
      "        [-7.6148e-01],\n",
      "        [-1.7003e-01],\n",
      "        [ 2.5025e+00],\n",
      "        [ 1.1443e+00],\n",
      "        [-2.7956e-01],\n",
      "        [ 5.2187e-03],\n",
      "        [-1.4812e-01],\n",
      "        [ 1.4072e+00],\n",
      "        [-1.6687e-02],\n",
      "        [-4.7671e-01],\n",
      "        [-6.0814e-01],\n",
      "        [-6.0814e-01],\n",
      "        [-1.9193e-01],\n",
      "        [-1.0244e+00],\n",
      "        [ 1.1475e-01],\n",
      "        [-1.0463e+00],\n",
      "        [-8.4911e-01],\n",
      "        [ 5.0905e-01],\n",
      "        [-5.2052e-01],\n",
      "        [-1.0463e+00],\n",
      "        [-1.7003e-01],\n",
      "        [-2.1384e-01],\n",
      "        [-3.8909e-01],\n",
      "        [-5.4243e-01],\n",
      "        [-6.9577e-01],\n",
      "        [-4.5480e-01],\n",
      "        [-6.0814e-01],\n",
      "        [ 4.2143e-01],\n",
      "        [-6.5195e-01],\n",
      "        [-1.4812e-01],\n",
      "        [-4.7671e-01],\n",
      "        [ 1.3665e-01],\n",
      "        [-1.2622e-01],\n",
      "        [-4.5480e-01],\n",
      "        [-6.3005e-01],\n",
      "        [-1.4812e-01],\n",
      "        [-5.2052e-01],\n",
      "        [ 2.1082e+00],\n",
      "        [ 5.0905e-01],\n",
      "        [ 3.3381e-01],\n",
      "        [-3.6718e-01],\n",
      "        [-3.4527e-01],\n",
      "        [-4.3290e-01],\n",
      "        [-7.3958e-01],\n",
      "        [-4.9861e-01],\n",
      "        [-3.8909e-01],\n",
      "        [-8.2404e-02],\n",
      "        [ 1.5856e-01],\n",
      "        [-2.7956e-01],\n",
      "        [ 1.4510e+00],\n",
      "        [ 2.6809e-01],\n",
      "        [-8.2404e-02],\n",
      "        [-1.7003e-01],\n",
      "        [ 1.1475e-01],\n",
      "        [-3.6718e-01],\n",
      "        [-6.5195e-01],\n",
      "        [ 1.3665e-01],\n",
      "        [-6.0814e-01],\n",
      "        [-6.9577e-01],\n",
      "        [ 3.3381e-01],\n",
      "        [-8.0529e-01],\n",
      "        [ 9.2842e-02],\n",
      "        [-2.1384e-01],\n",
      "        [-6.0499e-02],\n",
      "        [-2.1384e-01],\n",
      "        [-3.0146e-01],\n",
      "        [-2.5765e-01],\n",
      "        [ 1.8046e-01],\n",
      "        [-4.1099e-01],\n",
      "        [ 3.7762e-01],\n",
      "        [ 3.9952e-01],\n",
      "        [-8.2720e-01],\n",
      "        [-4.9861e-01],\n",
      "        [-4.1099e-01],\n",
      "        [-4.1099e-01],\n",
      "        [-6.5195e-01],\n",
      "        [ 1.3665e-01],\n",
      "        [-3.2337e-01],\n",
      "        [ 5.0905e-01],\n",
      "        [ 3.1190e-01],\n",
      "        [ 9.2842e-02],\n",
      "        [-2.7956e-01],\n",
      "        [-1.0463e+00],\n",
      "        [ 3.5571e-01],\n",
      "        [-6.3005e-01],\n",
      "        [-5.6433e-01],\n",
      "        [-1.9193e-01],\n",
      "        [ 2.7125e-02],\n",
      "        [ 5.3096e-01],\n",
      "        [ 6.6646e+00],\n",
      "        [-6.0499e-02],\n",
      "        [ 5.2187e-03],\n",
      "        [ 1.1005e+00],\n",
      "        [-4.3290e-01],\n",
      "        [-2.7956e-01],\n",
      "        [ 2.7125e-02],\n",
      "        [-8.2404e-02],\n",
      "        [-6.0814e-01],\n",
      "        [ 4.7588e+00],\n",
      "        [ 2.2428e-01],\n",
      "        [-4.3290e-01],\n",
      "        [-3.4527e-01],\n",
      "        [-1.0431e-01],\n",
      "        [ 3.7762e-01],\n",
      "        [-6.0814e-01],\n",
      "        [ 5.0905e-01],\n",
      "        [ 4.4333e-01],\n",
      "        [-9.3673e-01],\n",
      "        [-4.5480e-01],\n",
      "        [ 8.5954e-01],\n",
      "        [-4.5480e-01],\n",
      "        [-7.6148e-01],\n",
      "        [ 4.2143e-01],\n",
      "        [ 7.5001e-01],\n",
      "        [-1.9193e-01],\n",
      "        [ 2.4618e-01],\n",
      "        [-6.9577e-01],\n",
      "        [-5.8624e-01],\n",
      "        [-7.6148e-01],\n",
      "        [-3.0146e-01],\n",
      "        [ 2.2428e-01],\n",
      "        [-4.3290e-01],\n",
      "        [ 7.0936e-02],\n",
      "        [ 9.9098e-01],\n",
      "        [-5.8624e-01],\n",
      "        [-1.9193e-01],\n",
      "        [ 2.7125e-02],\n",
      "        [-8.2404e-02],\n",
      "        [ 7.2811e-01],\n",
      "        [-8.2404e-02],\n",
      "        [ 7.7192e-01],\n",
      "        [-1.6687e-02],\n",
      "        [ 7.0620e-01],\n",
      "        [-4.9861e-01],\n",
      "        [-1.6687e-02],\n",
      "        [-1.7003e-01],\n",
      "        [ 4.2143e-01],\n",
      "        [-6.0499e-02],\n",
      "        [-3.6718e-01],\n",
      "        [ 2.8999e-01],\n",
      "        [-1.2622e-01],\n",
      "        [-3.8909e-01],\n",
      "        [ 9.2842e-02],\n",
      "        [ 2.6809e-01],\n",
      "        [ 3.7762e-01],\n",
      "        [ 2.6809e-01],\n",
      "        [ 1.8453e+00],\n",
      "        [-3.2337e-01],\n",
      "        [-6.0499e-02],\n",
      "        [-6.9577e-01],\n",
      "        [-1.7003e-01],\n",
      "        [ 5.3096e-01],\n",
      "        [-8.2404e-02],\n",
      "        [-4.9861e-01],\n",
      "        [-3.4527e-01],\n",
      "        [ 5.5286e-01],\n",
      "        [-1.0463e+00],\n",
      "        [ 1.4510e+00],\n",
      "        [ 2.7125e-02],\n",
      "        [-1.6687e-02],\n",
      "        [-1.6687e-02],\n",
      "        [-4.9861e-01],\n",
      "        [-4.7671e-01],\n",
      "        [-4.3290e-01],\n",
      "        [ 3.3381e-01],\n",
      "        [-2.1384e-01],\n",
      "        [ 1.8046e-01],\n",
      "        [ 7.7192e-01],\n",
      "        [-4.7671e-01],\n",
      "        [ 3.1190e-01],\n",
      "        [-4.3290e-01],\n",
      "        [ 3.9952e-01],\n",
      "        [ 5.7477e-01],\n",
      "        [-3.4527e-01],\n",
      "        [-7.3958e-01],\n",
      "        [ 1.6043e+00],\n",
      "        [-4.9861e-01],\n",
      "        [-2.3574e-01],\n",
      "        [ 1.1881e+00],\n",
      "        [-5.2052e-01],\n",
      "        [ 1.5856e-01],\n",
      "        [-1.2622e-01],\n",
      "        [-2.1384e-01],\n",
      "        [ 5.2187e-03],\n",
      "        [-1.9193e-01],\n",
      "        [ 1.0348e+00],\n",
      "        [-4.3290e-01],\n",
      "        [-7.3958e-01],\n",
      "        [-2.1384e-01],\n",
      "        [-6.0814e-01],\n",
      "        [-4.3290e-01],\n",
      "        [-2.7956e-01],\n",
      "        [-3.2337e-01],\n",
      "        [ 2.2428e-01],\n",
      "        [-3.6718e-01],\n",
      "        [ 9.0336e-01],\n",
      "        [-4.1099e-01],\n",
      "        [-3.6718e-01],\n",
      "        [-1.0463e+00],\n",
      "        [ 7.5001e-01],\n",
      "        [-3.4527e-01],\n",
      "        [ 2.1958e+00],\n",
      "        [-1.7003e-01],\n",
      "        [-3.2337e-01],\n",
      "        [ 5.7477e-01],\n",
      "        [ 7.0936e-02],\n",
      "        [-4.1099e-01],\n",
      "        [ 1.1224e+00],\n",
      "        [ 4.2143e-01],\n",
      "        [ 3.5571e-01],\n",
      "        [ 6.1858e-01],\n",
      "        [-1.7003e-01],\n",
      "        [ 5.7477e-01],\n",
      "        [ 1.1881e+00],\n",
      "        [-2.3574e-01],\n",
      "        [-2.1384e-01],\n",
      "        [-1.0244e+00],\n",
      "        [ 1.1475e-01],\n",
      "        [-2.7956e-01],\n",
      "        [ 4.2143e-01],\n",
      "        [-4.7671e-01],\n",
      "        [-6.0499e-02],\n",
      "        [-1.0431e-01],\n",
      "        [-3.0146e-01],\n",
      "        [-7.8339e-01],\n",
      "        [ 1.3665e-01],\n",
      "        [-3.4527e-01],\n",
      "        [-3.6718e-01],\n",
      "        [-3.2337e-01],\n",
      "        [-4.5480e-01],\n",
      "        [ 1.3665e-01],\n",
      "        [ 5.3096e-01],\n",
      "        [ 7.0936e-02],\n",
      "        [-4.9861e-01],\n",
      "        [-3.4527e-01],\n",
      "        [-1.7003e-01],\n",
      "        [-1.7003e-01],\n",
      "        [-5.6433e-01],\n",
      "        [ 5.2187e-03],\n",
      "        [-1.0463e+00],\n",
      "        [ 1.8046e-01],\n",
      "        [-6.0499e-02],\n",
      "        [-6.0814e-01],\n",
      "        [ 2.0237e-01],\n",
      "        [-6.9577e-01],\n",
      "        [ 5.9667e-01],\n",
      "        [-6.9577e-01],\n",
      "        [-5.6433e-01],\n",
      "        [-4.5480e-01],\n",
      "        [ 1.5856e-01],\n",
      "        [-8.2404e-02],\n",
      "        [ 2.6809e-01],\n",
      "        [-5.2052e-01],\n",
      "        [-1.7003e-01],\n",
      "        [-5.4243e-01],\n",
      "        [-5.2052e-01],\n",
      "        [-8.2720e-01],\n",
      "        [-1.6687e-02],\n",
      "        [ 5.9667e-01],\n",
      "        [ 4.9030e-02],\n",
      "        [-4.5480e-01],\n",
      "        [-3.8909e-01],\n",
      "        [-6.5195e-01],\n",
      "        [-4.1099e-01],\n",
      "        [-3.4527e-01],\n",
      "        [ 4.6524e-01],\n",
      "        [ 2.0644e+00],\n",
      "        [ 4.4333e-01],\n",
      "        [-1.0463e+00],\n",
      "        [ 1.1475e-01],\n",
      "        [-4.7671e-01],\n",
      "        [ 5.7477e-01],\n",
      "        [-5.4243e-01],\n",
      "        [-2.1384e-01],\n",
      "        [-6.3005e-01],\n",
      "        [-6.9577e-01],\n",
      "        [ 7.2811e-01],\n",
      "        [ 3.1190e-01],\n",
      "        [ 1.5856e-01],\n",
      "        [-1.6687e-02],\n",
      "        [ 1.9767e+00],\n",
      "        [ 1.3634e+00],\n",
      "        [ 2.7125e-02],\n",
      "        [-2.3574e-01],\n",
      "        [-1.0431e-01],\n",
      "        [ 2.7125e-02],\n",
      "        [ 3.5571e-01],\n",
      "        [-1.6687e-02],\n",
      "        [ 1.8046e-01],\n",
      "        [-1.7003e-01],\n",
      "        [ 3.9483e+00],\n",
      "        [-5.8624e-01],\n",
      "        [-4.3290e-01],\n",
      "        [ 9.2842e-02],\n",
      "        [-3.0146e-01],\n",
      "        [ 3.3381e-01],\n",
      "        [-3.8593e-02],\n",
      "        [-1.2622e-01],\n",
      "        [ 7.9383e-01],\n",
      "        [ 5.2187e-03],\n",
      "        [ 9.2842e-02],\n",
      "        [-1.0431e-01],\n",
      "        [-6.3005e-01],\n",
      "        [-8.7101e-01],\n",
      "        [ 3.9952e-01],\n",
      "        [-3.6718e-01],\n",
      "        [-8.2404e-02],\n",
      "        [-1.9193e-01],\n",
      "        [-6.7386e-01],\n",
      "        [-7.6148e-01],\n",
      "        [ 1.8234e+00],\n",
      "        [-3.4527e-01],\n",
      "        [-3.6718e-01],\n",
      "        [-2.5765e-01],\n",
      "        [-4.5480e-01],\n",
      "        [ 3.5571e-01],\n",
      "        [ 7.9570e+00],\n",
      "        [-2.3574e-01],\n",
      "        [ 3.6416e+00],\n",
      "        [-4.7671e-01],\n",
      "        [-6.7386e-01],\n",
      "        [-1.0244e+00],\n",
      "        [-5.2052e-01],\n",
      "        [ 1.8015e+00],\n",
      "        [-7.1767e-01],\n",
      "        [ 2.6809e-01],\n",
      "        [-4.5480e-01],\n",
      "        [-3.8593e-02],\n",
      "        [-7.6148e-01],\n",
      "        [ 1.5856e-01],\n",
      "        [-7.1767e-01],\n",
      "        [-4.3290e-01],\n",
      "        [-6.0814e-01],\n",
      "        [-3.6718e-01],\n",
      "        [ 5.5286e-01],\n",
      "        [ 4.9030e-02],\n",
      "        [ 2.7125e-02],\n",
      "        [ 3.1190e-01],\n",
      "        [-4.7671e-01],\n",
      "        [-6.7386e-01],\n",
      "        [-1.0431e-01],\n",
      "        [ 9.2526e-01],\n",
      "        [ 6.6239e-01],\n",
      "        [ 3.3381e-01],\n",
      "        [-6.0499e-02],\n",
      "        [ 4.6524e-01],\n",
      "        [-4.3290e-01],\n",
      "        [-6.0499e-02],\n",
      "        [ 5.9667e-01],\n",
      "        [-4.3290e-01],\n",
      "        [-5.4243e-01],\n",
      "        [ 4.2143e-01],\n",
      "        [-3.8909e-01],\n",
      "        [-4.3290e-01],\n",
      "        [ 1.8453e+00],\n",
      "        [-4.7671e-01],\n",
      "        [-3.0146e-01],\n",
      "        [-3.0146e-01],\n",
      "        [ 3.3381e-01],\n",
      "        [ 1.8046e-01],\n",
      "        [-5.2052e-01],\n",
      "        [-2.5765e-01],\n",
      "        [-8.2404e-02],\n",
      "        [ 2.7125e-02],\n",
      "        [-6.0814e-01],\n",
      "        [-3.8909e-01],\n",
      "        [-1.0244e+00],\n",
      "        [-1.2622e-01],\n",
      "        [ 1.2758e+00],\n",
      "        [-8.2404e-02],\n",
      "        [ 1.5386e+00],\n",
      "        [-2.3574e-01],\n",
      "        [-3.8909e-01],\n",
      "        [-4.9861e-01],\n",
      "        [-6.3005e-01],\n",
      "        [ 3.9952e-01],\n",
      "        [-3.8909e-01],\n",
      "        [ 1.1224e+00],\n",
      "        [-3.0146e-01],\n",
      "        [-3.0146e-01],\n",
      "        [ 7.0936e-02],\n",
      "        [ 3.1190e-01],\n",
      "        [-4.3290e-01],\n",
      "        [-2.3574e-01],\n",
      "        [-8.2404e-02],\n",
      "        [ 3.3381e-01],\n",
      "        [ 3.7762e-01],\n",
      "        [ 4.8715e-01],\n",
      "        [ 7.7192e-01],\n",
      "        [ 4.9030e-02],\n",
      "        [ 7.7192e-01],\n",
      "        [-2.3574e-01],\n",
      "        [ 2.8999e-01],\n",
      "        [-3.8909e-01],\n",
      "        [ 5.5286e-01],\n",
      "        [ 3.7762e-01],\n",
      "        [ 4.9030e-02],\n",
      "        [ 2.7125e-02],\n",
      "        [-1.0244e+00],\n",
      "        [-3.6718e-01],\n",
      "        [-8.2404e-02],\n",
      "        [ 2.2428e-01],\n",
      "        [-6.9577e-01],\n",
      "        [-1.7003e-01],\n",
      "        [ 2.0237e-01],\n",
      "        [-3.4527e-01],\n",
      "        [-5.2052e-01],\n",
      "        [-3.4527e-01],\n",
      "        [-1.0431e-01],\n",
      "        [ 2.4618e-01],\n",
      "        [ 1.9986e+00],\n",
      "        [-7.6148e-01],\n",
      "        [ 5.3096e-01],\n",
      "        [ 1.1443e+00],\n",
      "        [ 5.2187e-03],\n",
      "        [ 1.5824e+00],\n",
      "        [ 9.4717e-01],\n",
      "        [ 1.3415e+00],\n",
      "        [ 4.9030e-02],\n",
      "        [-5.2052e-01],\n",
      "        [ 3.3381e-01],\n",
      "        [ 2.2834e+00],\n",
      "        [-3.4527e-01],\n",
      "        [-6.0814e-01],\n",
      "        [-7.1767e-01],\n",
      "        [-4.3290e-01],\n",
      "        [-4.9861e-01],\n",
      "        [ 9.2842e-02],\n",
      "        [-5.6433e-01],\n",
      "        [-1.9193e-01],\n",
      "        [ 2.0237e-01],\n",
      "        [ 1.1475e-01],\n",
      "        [ 1.1475e-01],\n",
      "        [-6.7386e-01],\n",
      "        [-1.0431e-01],\n",
      "        [-6.9577e-01],\n",
      "        [-5.6433e-01],\n",
      "        [-1.6687e-02],\n",
      "        [-3.0146e-01],\n",
      "        [ 2.2428e-01],\n",
      "        [-6.7386e-01],\n",
      "        [-3.2337e-01],\n",
      "        [ 2.0237e-01],\n",
      "        [-5.2052e-01],\n",
      "        [-7.6148e-01],\n",
      "        [-2.5765e-01],\n",
      "        [ 4.4333e-01],\n",
      "        [-6.9577e-01],\n",
      "        [-5.4243e-01],\n",
      "        [-6.7386e-01],\n",
      "        [-5.2052e-01],\n",
      "        [-4.5480e-01],\n",
      "        [-1.0431e-01],\n",
      "        [ 4.2143e-01],\n",
      "        [ 5.0905e-01],\n",
      "        [ 3.9952e-01],\n",
      "        [-4.7671e-01],\n",
      "        [-4.1099e-01],\n",
      "        [ 5.2187e-03],\n",
      "        [-7.6148e-01],\n",
      "        [-6.0499e-02],\n",
      "        [-4.9861e-01],\n",
      "        [-1.0431e-01],\n",
      "        [-2.3574e-01],\n",
      "        [ 5.3096e-01],\n",
      "        [ 1.2758e+00],\n",
      "        [-4.5480e-01],\n",
      "        [ 1.8046e-01],\n",
      "        [-4.1099e-01],\n",
      "        [-2.1384e-01],\n",
      "        [-4.7671e-01],\n",
      "        [ 6.8430e-01],\n",
      "        [-7.3958e-01],\n",
      "        [-1.0463e+00],\n",
      "        [ 1.1475e-01],\n",
      "        [-5.4243e-01],\n",
      "        [ 3.1190e-01],\n",
      "        [ 4.9030e-02],\n",
      "        [-3.4527e-01],\n",
      "        [-2.3574e-01],\n",
      "        [-2.5765e-01],\n",
      "        [ 2.5901e+00],\n",
      "        [ 2.2428e-01],\n",
      "        [-3.6718e-01],\n",
      "        [ 4.4333e-01],\n",
      "        [ 9.2526e-01],\n",
      "        [-4.5480e-01],\n",
      "        [ 7.7192e-01],\n",
      "        [-8.2404e-02],\n",
      "        [ 1.2100e+00],\n",
      "        [ 5.5286e-01],\n",
      "        [ 5.7477e-01],\n",
      "        [-5.2052e-01],\n",
      "        [-1.9193e-01],\n",
      "        [ 2.8999e-01],\n",
      "        [-3.8909e-01],\n",
      "        [ 5.0905e-01],\n",
      "        [ 4.9030e-02],\n",
      "        [-3.6718e-01],\n",
      "        [-6.0499e-02],\n",
      "        [ 1.2977e+00],\n",
      "        [-9.1482e-01],\n",
      "        [-2.3574e-01],\n",
      "        [ 5.0905e-01],\n",
      "        [-8.2404e-02],\n",
      "        [-2.1384e-01],\n",
      "        [-2.1384e-01],\n",
      "        [ 2.7434e+00],\n",
      "        [-5.8624e-01],\n",
      "        [ 5.2187e-03],\n",
      "        [-1.0463e+00],\n",
      "        [ 5.2187e-03],\n",
      "        [-2.3574e-01],\n",
      "        [-3.8593e-02],\n",
      "        [-3.8909e-01],\n",
      "        [ 2.2428e-01],\n",
      "        [-3.2337e-01],\n",
      "        [-1.0431e-01],\n",
      "        [-4.3290e-01],\n",
      "        [-4.1099e-01],\n",
      "        [-4.9861e-01],\n",
      "        [ 9.2842e-02],\n",
      "        [ 3.3381e-01],\n",
      "        [-1.9193e-01],\n",
      "        [-2.3574e-01],\n",
      "        [-1.0244e+00],\n",
      "        [-5.2052e-01],\n",
      "        [-8.2404e-02],\n",
      "        [-3.8909e-01],\n",
      "        [ 2.2428e-01],\n",
      "        [-5.2052e-01],\n",
      "        [ 3.5571e-01],\n",
      "        [-6.3005e-01],\n",
      "        [ 1.8046e-01],\n",
      "        [-4.5480e-01],\n",
      "        [ 4.2143e-01],\n",
      "        [-3.8909e-01],\n",
      "        [ 1.1475e-01],\n",
      "        [ 2.0237e-01],\n",
      "        [-3.2337e-01],\n",
      "        [-3.2337e-01],\n",
      "        [ 9.2526e-01],\n",
      "        [ 3.7762e-01],\n",
      "        [-1.0431e-01],\n",
      "        [-7.3958e-01],\n",
      "        [-1.0024e+00],\n",
      "        [ 2.4618e-01],\n",
      "        [ 2.4618e-01],\n",
      "        [-5.2052e-01],\n",
      "        [ 7.5001e-01],\n",
      "        [ 5.3096e-01],\n",
      "        [ 9.2526e-01],\n",
      "        [ 4.6524e-01],\n",
      "        [-7.1767e-01],\n",
      "        [-6.0499e-02],\n",
      "        [-1.0463e+00],\n",
      "        [ 2.0237e-01],\n",
      "        [-8.0529e-01],\n",
      "        [-4.1099e-01],\n",
      "        [-4.5480e-01],\n",
      "        [-1.9193e-01],\n",
      "        [ 1.0129e+00],\n",
      "        [-6.0814e-01],\n",
      "        [-6.0499e-02],\n",
      "        [-7.3958e-01],\n",
      "        [ 6.4049e-01],\n",
      "        [-1.0463e+00],\n",
      "        [-2.7956e-01],\n",
      "        [ 7.0620e-01],\n",
      "        [-5.8624e-01],\n",
      "        [-3.6718e-01],\n",
      "        [ 1.5167e+00],\n",
      "        [-7.3958e-01],\n",
      "        [ 1.3665e-01],\n",
      "        [-3.2337e-01],\n",
      "        [-2.3574e-01],\n",
      "        [-1.7003e-01],\n",
      "        [ 2.7125e-02],\n",
      "        [ 5.9667e-01],\n",
      "        [ 4.2143e-01],\n",
      "        [-3.8909e-01],\n",
      "        [ 5.2187e-03],\n",
      "        [-4.5480e-01],\n",
      "        [-1.4812e-01],\n",
      "        [-2.1384e-01],\n",
      "        [ 1.3665e-01],\n",
      "        [-6.5195e-01],\n",
      "        [-6.0499e-02],\n",
      "        [-3.8593e-02],\n",
      "        [ 3.7762e-01],\n",
      "        [ 4.9030e-02],\n",
      "        [-7.6148e-01],\n",
      "        [ 1.7358e+00],\n",
      "        [-6.0499e-02],\n",
      "        [-4.3290e-01],\n",
      "        [-1.0463e+00],\n",
      "        [-3.8593e-02],\n",
      "        [-3.4527e-01],\n",
      "        [-4.9861e-01],\n",
      "        [-1.7003e-01],\n",
      "        [-5.6433e-01],\n",
      "        [ 6.8430e-01],\n",
      "        [ 9.2526e-01],\n",
      "        [-4.3290e-01],\n",
      "        [ 2.7125e-02],\n",
      "        [-6.0814e-01],\n",
      "        [ 6.8430e-01],\n",
      "        [-1.0463e+00],\n",
      "        [ 2.8999e-01],\n",
      "        [-4.9861e-01],\n",
      "        [ 3.3381e-01],\n",
      "        [-2.1384e-01],\n",
      "        [ 4.9030e-02],\n",
      "        [-3.8593e-02],\n",
      "        [-6.5195e-01],\n",
      "        [-6.0499e-02],\n",
      "        [ 3.7762e-01],\n",
      "        [-5.2052e-01],\n",
      "        [ 2.4618e-01],\n",
      "        [ 2.0237e-01],\n",
      "        [-2.3574e-01],\n",
      "        [ 2.6809e-01],\n",
      "        [ 8.1573e-01],\n",
      "        [-1.4812e-01],\n",
      "        [-1.0463e+00],\n",
      "        [ 4.9030e-02],\n",
      "        [ 3.5571e-01],\n",
      "        [ 1.0348e+00],\n",
      "        [-3.4527e-01],\n",
      "        [-2.1384e-01],\n",
      "        [-1.0463e+00],\n",
      "        [-1.0463e+00],\n",
      "        [-4.5480e-01],\n",
      "        [-8.4911e-01],\n",
      "        [ 3.9952e-01],\n",
      "        [ 7.0936e-02],\n",
      "        [-4.5480e-01],\n",
      "        [ 2.7125e-02],\n",
      "        [-5.2052e-01],\n",
      "        [-6.0499e-02],\n",
      "        [ 2.0237e-01]])\n"
     ]
    }
   ],
   "source": [
    "x, y = next(iter(train_iterator))\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KZuPIyvN4O9b"
   },
   "source": [
    "### Defining the Model\n",
    "\n",
    "Our model will be a neural network, specifically a multilayer perceptron (MLP) with two hidden layers. The image below shows the archicture of the model. \n",
    "\n",
    "The transformation between 784 to 250, 250 to 100 and 100 to 10 dimensions are done by `Linear` layers. These are also known as fully connected or affine layers. In these layers, every element in one layer is connected to every element in the next. We can think of these elements as *neurons*, as this architecture is inspired by how the human brain is made of millions of interconnected nodes, also called neurons. \n",
    "\n",
    "Each connection between a neuron in one layer and a neuron in the next has a *weight* associated with it. The input to one neuron is the sum of the weighted values of all neurons in the previous layer connected to it, plus a weighted bias term, where the bias value is always 1. The neuron then applies an *activation function* to this weighted sum. This activation function is a non-linear function that allows the neural network to learn non-linear functions between inputs and outputs. \n",
    "\n",
    "We define our MLP below, which consists of three linear layers. We first take the input batch of images and flatten them, so they can be passed into the linear layers. We then pass them through the first linear layer, `input_fc`, which calculates the weighted sum of the inputs, and then apply the *ReLU* (rectified linear unit) activation function elementwise. This result is then passed through another linear layer, `hidden_fc`, again applying the same activation function elementwise. Finally, we pass this through the final linear layer, `output_fc`. We return not only the output but also the second hidden layer as we will do some analysis on it later.\n",
    "\n",
    "One thing to note is that we do not use an activation function on the input directly or on the output. You should never use activation functions directly on the input, i.e. `F.relu(x)`. PyTorch combines activation functions to be applied on the output with the functions which calculate the *loss*, also known as *error* or *cost*, of a neural network. This is done for numerical stability.\n",
    "\n",
    "Why did we choose hidden dimensions of 250 and 100 elements? Why did we only have two hidden layers? There is no magic formula to tell us how many layers to use and how many neurons to have in each layer, and there is most probably a better set of values. However, the general idea is that neural networks extract features from data. Layers closer to the input learn to extract general features (e.g. lines, curves, edges), whilst later layers combine the features extracted from the previous layer into more high level features (e.g. the intersection of two lines making a cross, multiple curves make a circle). We force our neural network to learn these features by reducing the number of neurons in each layer. This way, it has to learn to compress information by extracting only the useful and general features. Thus, we want a neural network with multiple layers and some sort of information compression (reduced number of neurons in subsequent layers).\n",
    "\n",
    "# MODEL STRUCTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "lAqzcW9XREvu"
   },
   "outputs": [],
   "source": [
    "input_dim, output_dim = 5, 1\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LinearRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "\n",
    "model = LinearRegressionModel(input_dim, output_dim)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FgPqWhK-4O9f"
   },
   "source": [
    "We'll define our model by creating an instance of it and setting the correct input and output dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F3bacWHd4O9j"
   },
   "source": [
    "We can also create a small function to calculate the number of trainable parameters (weights and biases) in our model - in case all of our parameters are trainable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "1gF2fmTBREv8"
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gik6Q5ZB4O9q"
   },
   "source": [
    "The first layer has 784 neurons connected to 250 neurons, so 784*250 weighted connections plus 250 bias terms.\n",
    "\n",
    "The second layer has 250 neurons connected to 100 neurons, 250*100 weighted connections plus 100 bias terms.\n",
    "\n",
    "The third layer has 100 neurons connected to 10 neurons, 100*10 weighted connections plus 10 bias terms.\n",
    "\n",
    "$$784 \\cdot 250 + 250 + 250 \\cdot 100 + 100 + 100 \\cdot 10 + 10 = 222,360 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "8N1iy4Sji4jl",
    "outputId": "753725c3-7394-4254-f8ca-073dc08648ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 6 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IiL9hZqX4O9x"
   },
   "source": [
    "### Training the Model\n",
    "\n",
    "Next, we'll define our optimizer. This is the algorithm we will use to update the parameters of our model with respect to the loss calculated on the data.\n",
    "\n",
    "We aren't going to go into too much detail on how neural networks are trained (see [this](http://neuralnetworksanddeeplearning.com/) article if you want to know how) but the gist is:\n",
    "- pass a batch of data through your model\n",
    "- calculate the loss of your batch by comparing your model's predictions against the actual labels\n",
    "- calculate the gradient of each of your parameters with respect to the loss\n",
    "- update each of your parameters by subtracting their gradient multiplied by a small *learning rate* parameter\n",
    "\n",
    "We use the *Adam* algorithm with the default parameters to update our model. Improved results could be obtained by searching over different optimizers and learning rates, however default Adam is usually a good starting off point. Check out [this](https://ruder.io/optimizing-gradient-descent/) article if you want to learn more about the different optimization algorithms commonly used for neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gBvdk2RR4O95"
   },
   "source": [
    "# LOSS FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "OO2BL-qBREwD"
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dwKdgFmU4O-A"
   },
   "source": [
    "We then define `device`. This is used to place your model and data on to a GPU, if you have one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "7QgyFD6gREwH"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qzKopDSd4O-F"
   },
   "source": [
    "We place our model and criterion on to the device by using the `.to` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "FTvjOcbLREwM"
   },
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPTIMIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "eC2P8WJuREv_"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adagrad(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bd0F_7i_4O-M"
   },
   "source": [
    "Next, we'll define a function to calculate the accuracy of our model. This takes the index of the highest value for your prediction and compares it against the actual class label. We then divide how many our model got correct by the amount in the batch to calculate accuracy across the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "VkttGrmkREwP"
   },
   "outputs": [],
   "source": [
    "def calculate_accuracy(y_pred, y):\n",
    "    '''top_pred = y_pred.argmax(1, keepdim=True)\n",
    "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
    "    acc = correct.float() / y.shape[0]'''\n",
    "    return 0 #acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d3T0oPWh4O-R"
   },
   "source": [
    "We finally define our training loop.\n",
    "\n",
    "This will:\n",
    "- put our model into `train` mode\n",
    "- iterate over our dataloader, returning batches of (image, label)\n",
    "- place the batch on to our GPU, if we have one\n",
    "- clear the gradients calculated from the last batch\n",
    "- pass our batch of images, `x`, through to model to get predictions, `y_pred`\n",
    "- calculate the loss between our predictions and the actual labels\n",
    "- calculate the accuracy between our predictions and the actual labels\n",
    "- calculate the gradients of each parameter\n",
    "- update the parameters by taking an optimizer step\n",
    "- update our metrics\n",
    "\n",
    "Some layers act differently when training and evaluating the model that contains them, hence why we must tell our model we are in \"training\" mode. The model we are using here does not use any of those layers, however it is good practice to get used to putting your model in training mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0kCtKBMfREwS"
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, device):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for (x, y) in tqdm(iterator, desc=\"Training\", leave=False):\n",
    "\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred = model(x)\n",
    "\n",
    "        loss = criterion(y_pred, y)\n",
    "\n",
    "        acc = calculate_accuracy(y_pred, y)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += 0 #acc.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9kuF4-Cx4O-X"
   },
   "source": [
    "The evaluation loop is similar to the training loop. The differences are:\n",
    "- we put our model into evaluation mode with `model.eval()`\n",
    "- we wrap the iterations inside a `with torch.no_grad()`\n",
    "- we do not zero gradients as we are not calculating any\n",
    "- we do not calculate gradients as we are not updating parameters\n",
    "- we do not take an optimizer step as we are not calculating gradients\n",
    "\n",
    "`torch.no_grad()` ensures that gradients are not calculated for whatever is inside the `with` block. As our model will not have to calculate gradients, it will be faster and use less memory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "3XL4sRI8REwV"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion, device):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for (x, y) in tqdm(iterator, desc=\"Evaluating\", leave=False):\n",
    "\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            y_pred = model(x)\n",
    "\n",
    "            loss = criterion(y_pred, y)\n",
    "\n",
    "            acc = calculate_accuracy(y_pred, y)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += 0 #acc.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dySDirym4O-c"
   },
   "source": [
    "The final step before training is to define a small function to tell us how long an epoch took."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "ENrsvnEZREwZ"
   },
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uHn-rDvA4O-h"
   },
   "source": [
    "We're finally ready to train!\n",
    "\n",
    "During each epoch we calculate the training loss and accuracy, followed by the validation loss and accuracy. We then check if the validation loss achieved is the best validation loss we have seen. If so, we save our model's parameters (called a `state_dict`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NUMBER OF EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 557
    },
    "id": "p-gtfzafREwc",
    "outputId": "a1314661-c18c-4de6-d6f5-89541165199e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6019ac782544b9483deb3b22af395c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1626 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 15s\n",
      "\tTrain Loss: 0.980 | Train Acc: 0.00%\n",
      "\t Val. Loss: 0.850 |  Val. Acc: 0.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1626 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Epoch Time: 0m 13s\n",
      "\tTrain Loss: 0.952 | Train Acc: 0.00%\n",
      "\t Val. Loss: 0.841 |  Val. Acc: 0.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1626 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Epoch Time: 0m 12s\n",
      "\tTrain Loss: 0.947 | Train Acc: 0.00%\n",
      "\t Val. Loss: 0.838 |  Val. Acc: 0.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1626 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Epoch Time: 0m 12s\n",
      "\tTrain Loss: 0.943 | Train Acc: 0.00%\n",
      "\t Val. Loss: 0.837 |  Val. Acc: 0.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1626 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Epoch Time: 0m 12s\n",
      "\tTrain Loss: 0.942 | Train Acc: 0.00%\n",
      "\t Val. Loss: 0.836 |  Val. Acc: 0.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1626 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06 | Epoch Time: 0m 13s\n",
      "\tTrain Loss: 0.942 | Train Acc: 0.00%\n",
      "\t Val. Loss: 0.836 |  Val. Acc: 0.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1626 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07 | Epoch Time: 0m 11s\n",
      "\tTrain Loss: 0.941 | Train Acc: 0.00%\n",
      "\t Val. Loss: 0.836 |  Val. Acc: 0.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1626 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08 | Epoch Time: 0m 12s\n",
      "\tTrain Loss: 0.941 | Train Acc: 0.00%\n",
      "\t Val. Loss: 0.836 |  Val. Acc: 0.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1626 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09 | Epoch Time: 0m 12s\n",
      "\tTrain Loss: 0.953 | Train Acc: 0.00%\n",
      "\t Val. Loss: 0.836 |  Val. Acc: 0.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1626 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Epoch Time: 0m 12s\n",
      "\tTrain Loss: 0.941 | Train Acc: 0.00%\n",
      "\t Val. Loss: 0.836 |  Val. Acc: 0.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1626 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 | Epoch Time: 0m 12s\n",
      "\tTrain Loss: 0.941 | Train Acc: 0.00%\n",
      "\t Val. Loss: 0.836 |  Val. Acc: 0.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1626 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 | Epoch Time: 0m 12s\n",
      "\tTrain Loss: 0.941 | Train Acc: 0.00%\n",
      "\t Val. Loss: 0.836 |  Val. Acc: 0.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1626 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 | Epoch Time: 0m 12s\n",
      "\tTrain Loss: 0.941 | Train Acc: 0.00%\n",
      "\t Val. Loss: 0.836 |  Val. Acc: 0.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1626 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 | Epoch Time: 0m 12s\n",
      "\tTrain Loss: 0.941 | Train Acc: 0.00%\n",
      "\t Val. Loss: 0.836 |  Val. Acc: 0.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1626 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 | Epoch Time: 0m 12s\n",
      "\tTrain Loss: 0.941 | Train Acc: 0.00%\n",
      "\t Val. Loss: 0.836 |  Val. Acc: 0.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1626 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 | Epoch Time: 0m 12s\n",
      "\tTrain Loss: 0.941 | Train Acc: 0.00%\n",
      "\t Val. Loss: 0.836 |  Val. Acc: 0.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1626 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 | Epoch Time: 0m 12s\n",
      "\tTrain Loss: 0.941 | Train Acc: 0.00%\n",
      "\t Val. Loss: 0.836 |  Val. Acc: 0.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1626 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 | Epoch Time: 0m 12s\n",
      "\tTrain Loss: 0.941 | Train Acc: 0.00%\n",
      "\t Val. Loss: 0.836 |  Val. Acc: 0.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1626 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 | Epoch Time: 0m 12s\n",
      "\tTrain Loss: 0.941 | Train Acc: 0.00%\n",
      "\t Val. Loss: 0.836 |  Val. Acc: 0.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1626 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 | Epoch Time: 0m 12s\n",
      "\tTrain Loss: 0.941 | Train Acc: 0.00%\n",
      "\t Val. Loss: 0.836 |  Val. Acc: 0.00%\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in trange(EPOCHS):\n",
    "\n",
    "    start_time = time.monotonic()\n",
    "\n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion, device)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion, device)\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
    "\n",
    "    end_time = time.monotonic()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bBYcKw8Y4O-k"
   },
   "source": [
    "Afterwards, we load our the parameters of the model that achieved the best validation loss and then use this to evaluate our model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "VGDeNGLhREwf"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('tut1-model.pt'))\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tUPPCMA34O-p"
   },
   "source": [
    "Our model achieves 98% accuracy on the test set.\n",
    "\n",
    "This can be improved by tweaking hyperparameters, e.g. number of layers, number of neurons per layer, optimization algorithm used, learning rate, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "WrRhzovQRho5",
    "outputId": "87424d6b-9007-4b7b-d259-d05fdf040d3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.702 | Test Acc: 0.00%\n"
     ]
    }
   ],
   "source": [
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_data = CustomDataset(\"test_engineered.csv\")\n",
    "test_iterator = data.DataLoader(test_data,\n",
    "                                batch_size=BATCH_SIZE)\n",
    "\n",
    "df_result = pd.read_csv(\"sampleSubmission.csv\", index_col = False)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "mean = 716.4264615618442\n",
    "sd = 684.7511617508213\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for (x, y) in tqdm(test_iterator, desc=\"Evaluating\", leave=False):\n",
    "\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        y_pred = model(x)\n",
    "        \n",
    "        df_result['TRAVEL_TIME'] = pd.DataFrame(y_pred.cpu().numpy())\n",
    "        df_result['TRAVEL_TIME'] = df_result['TRAVEL_TIME'].apply(lambda x : (x * sd) + mean)\n",
    "\n",
    "df_result.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>TRAVEL_TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1</td>\n",
       "      <td>821.783940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T2</td>\n",
       "      <td>781.417559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T3</td>\n",
       "      <td>729.839605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T4</td>\n",
       "      <td>743.122130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T5</td>\n",
       "      <td>749.977171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>T323</td>\n",
       "      <td>650.889064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>T324</td>\n",
       "      <td>637.075509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>T325</td>\n",
       "      <td>821.545146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>T326</td>\n",
       "      <td>657.896123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>T327</td>\n",
       "      <td>662.347928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    TRIP_ID  TRAVEL_TIME\n",
       "0        T1   821.783940\n",
       "1        T2   781.417559\n",
       "2        T3   729.839605\n",
       "3        T4   743.122130\n",
       "4        T5   749.977171\n",
       "..      ...          ...\n",
       "315    T323   650.889064\n",
       "316    T324   637.075509\n",
       "317    T325   821.545146\n",
       "318    T326   657.896123\n",
       "319    T327   662.347928\n",
       "\n",
       "[320 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AeInowvn4O-0"
   },
   "source": [
    "### Examining the Model\n",
    "\n",
    "Now we've trained our model, there are a few things we can look at. Most of these are simple exploratory analysis, but they can offer some insights into your model.\n",
    "\n",
    "An important thing to do is check what examples your model gets wrong and ensure that they're reasonable mistakes.\n",
    "\n",
    "The function below will return the model's predictions over a given dataset. It will return the inputs (image) the outputs (model predictions) and the ground truth labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cK-f6JLGNp2u"
   },
   "outputs": [],
   "source": [
    "def get_predictions(model, iterator, device):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    images = []\n",
    "    labels = []\n",
    "    probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for (x, y) in iterator:\n",
    "\n",
    "            x = x.to(device)\n",
    "\n",
    "            y_pred, _ = model(x)\n",
    "\n",
    "            y_prob = F.softmax(y_pred, dim=-1)\n",
    "\n",
    "            images.append(x.cpu())\n",
    "            labels.append(y.cpu())\n",
    "            probs.append(y_prob.cpu())\n",
    "\n",
    "    images = torch.cat(images, dim=0)\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "    probs = torch.cat(probs, dim=0)\n",
    "\n",
    "    return images, labels, probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mwO_bDPTOGFG"
   },
   "source": [
    "We can then get these predictions and, by taking the index of the highest predicted probability, get the predicted labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jRqKe4PNognL"
   },
   "outputs": [],
   "source": [
    "images, labels, probs = get_predictions(model, test_iterator, device)\n",
    "\n",
    "pred_labels = torch.argmax(probs, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0lVdWZ4gOr2R"
   },
   "source": [
    "Then, we can make a confusion matrix from our actual labels and our predicted labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S8HvTwi5qgmG"
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(labels, pred_labels):\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    cm = metrics.confusion_matrix(labels, pred_labels)\n",
    "    cm = metrics.ConfusionMatrixDisplay(cm, display_labels=range(10))\n",
    "    cm.plot(values_format='d', cmap='Blues', ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KgBX_wx7-B4D"
   },
   "source": [
    "The results seem reasonable enough, the most confused predictions-actuals are: 3-5 and 2-7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 580
    },
    "id": "C6gprB1sO7fy",
    "outputId": "c71d372a-8b94-4573-9239-b7b0825b2208"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The number of FixedLocator locations (97), usually from a call to set_ticks, does not match the number of ticklabels (10).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8461/3495473412.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_8461/4085194355.py\u001b[0m in \u001b[0;36mplot_confusion_matrix\u001b[0;34m(labels, pred_labels)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConfusionMatrixDisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Blues'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_plot/confusion_matrix.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, include_values, cmap, xticks_rotation, values_format, ax, colorbar)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcolorbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolorbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         ax.set(xticks=np.arange(n_classes),\n\u001b[0m\u001b[1;32m    154\u001b[0m                \u001b[0myticks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                \u001b[0mxticklabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisplay_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmove_color_to_start\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"color\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"color\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1179\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfindobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_self\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, props)\u001b[0m\n\u001b[1;32m   1062\u001b[0m                         raise AttributeError(f\"{type(self).__name__!r} object \"\n\u001b[1;32m   1063\u001b[0m                                              f\"has no property {k!r}\")\n\u001b[0;32m-> 1064\u001b[0;31m                     \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1065\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpchanged\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mget_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mowner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/matplotlib/_api/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    469\u001b[0m                 \u001b[0;34m\"parameter will become keyword-only %(removal)s.\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m                 name=name, obj_type=f\"parameter of {func.__name__}()\")\n\u001b[0;32m--> 471\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_set_ticklabels\u001b[0;34m(self, labels, fontdict, minor, **kwargs)\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfontdict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1789\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfontdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1790\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ticklabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mminor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1791\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1792\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mticks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mset_ticklabels\u001b[0;34m(self, ticklabels, minor, **kwargs)\u001b[0m\n\u001b[1;32m   1709\u001b[0m             \u001b[0;31m# remove all tick labels, so only error for > 0 ticklabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticklabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticklabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1711\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m   1712\u001b[0m                     \u001b[0;34m\"The number of FixedLocator locations\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1713\u001b[0m                     \u001b[0;34mf\" ({len(locator.locs)}), usually from a call to\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The number of FixedLocator locations (97), usually from a call to set_ticks, does not match the number of ticklabels (10)."
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(labels, pred_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hgWqvvPg4O-9"
   },
   "source": [
    "Next, for each of our examples, we can check if our predicted label matches our actual label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FKTDsxMhvXv_"
   },
   "outputs": [],
   "source": [
    "corrects = torch.eq(labels, pred_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p0O_8iZxPBtW"
   },
   "source": [
    "We can then loop through all of the examples over our model's predictions and store all the examples the model got incorrect into an array.\n",
    "\n",
    "Then, we sort these incorrect examples by how confident they were, with the most confident being first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EAAZKuyYPCi3"
   },
   "outputs": [],
   "source": [
    "incorrect_examples = []\n",
    "\n",
    "for image, label, prob, correct in zip(images, labels, probs, corrects):\n",
    "    if not correct:\n",
    "        incorrect_examples.append((image, label, prob))\n",
    "\n",
    "incorrect_examples.sort(reverse=True,\n",
    "                        key=lambda x: torch.max(x[2], dim=0).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gbq9Yjki4O_E"
   },
   "source": [
    "We can then plot the incorrectly predicted images along with how confident they were on the actual label and how confident they were at the incorrect label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EDFDmbbQ1oRF"
   },
   "outputs": [],
   "source": [
    "def plot_most_incorrect(incorrect, n_images):\n",
    "\n",
    "    rows = int(np.sqrt(n_images))\n",
    "    cols = int(np.sqrt(n_images))\n",
    "\n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "    for i in range(rows*cols):\n",
    "        ax = fig.add_subplot(rows, cols, i+1)\n",
    "        image, true_label, probs = incorrect[i]\n",
    "        true_prob = probs[true_label]\n",
    "        incorrect_prob, incorrect_label = torch.max(probs, dim=0)\n",
    "        ax.imshow(image.view(28, 28).cpu().numpy(), cmap='bone')\n",
    "        ax.set_title(f'true label: {true_label} ({true_prob:.3f})\\n'\n",
    "                     f'pred label: {incorrect_label} ({incorrect_prob:.3f})')\n",
    "        ax.axis('off')\n",
    "    fig.subplots_adjust(hspace=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZNUqTyZ94O_J"
   },
   "source": [
    "Below we can see the 25 images the model got incorrect and was most confident about.\n",
    "\n",
    "A lot of these digits are irregular, so it's difficult for the model to do well on these. The images that do look fine, if you squint you can sort of see why the model got it wrong.\n",
    "\n",
    "Why is the neural network so confident on the irregular digits? Surely if it's a weird looking digit then the output of the softmax should be close to evenly distributed across a few digits the model isn't sure about, right? Well, no. The model has been trained to only be incredibly confident about its predictions, and thus when it sees an image it will always be confident about what it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 606
    },
    "id": "HtZG13Ui6aYT",
    "outputId": "0c02244e-43d5-4871-8397-b0b2fe7ef8c9"
   },
   "outputs": [],
   "source": [
    "N_IMAGES = 25\n",
    "\n",
    "plot_most_incorrect(incorrect_examples, N_IMAGES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t6yj_pS14O_P"
   },
   "source": [
    "Another thing we can do is get the output and intermediate representations from the model and try to visualize them.\n",
    "\n",
    "The function below loops through the provided dataset and gets the output from the model and the intermediate representation from the layer before that, the second hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XslX4Zd_TiGu"
   },
   "outputs": [],
   "source": [
    "def get_representations(model, iterator, device):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    outputs = []\n",
    "    intermediates = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for (x, y) in tqdm(iterator):\n",
    "\n",
    "            x = x.to(device)\n",
    "\n",
    "            y_pred, h = model(x)\n",
    "\n",
    "            outputs.append(y_pred.cpu())\n",
    "            intermediates.append(h.cpu())\n",
    "            labels.append(y)\n",
    "\n",
    "    outputs = torch.cat(outputs, dim=0)\n",
    "    intermediates = torch.cat(intermediates, dim=0)\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "\n",
    "    return outputs, intermediates, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NabFzvWf4O_U"
   },
   "source": [
    "We run the function to get the representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cOGCUKbzV_T7"
   },
   "outputs": [],
   "source": [
    "outputs, intermediates, labels = get_representations(model,\n",
    "                                                     train_iterator,\n",
    "                                                     device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CPxcxsYm4O_Z"
   },
   "source": [
    "The data we want to visualize is in ten dimensions and 100 dimensions. We want to get this down to two dimensions, so we can actually plot it. \n",
    "\n",
    "The first technique we'll use is PCA (principal component analysis). First, we'll define a function to calculate the PCA of our data, and then we'll define a function to plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fN1ZIyWcUDgV"
   },
   "outputs": [],
   "source": [
    "def get_pca(data, n_components=2):\n",
    "    pca = decomposition.PCA()\n",
    "    pca.n_components = n_components\n",
    "    pca_data = pca.fit_transform(data)\n",
    "    return pca_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eIgm25aDXFJe"
   },
   "outputs": [],
   "source": [
    "def plot_representations(data, labels, n_images=None):\n",
    "    if n_images is not None:\n",
    "        data = data[:n_images]\n",
    "        labels = labels[:n_images]\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    scatter = ax.scatter(data[:, 0], data[:, 1], c=labels, cmap='tab10')\n",
    "    handles, labels = scatter.legend_elements()\n",
    "    ax.legend(handles=handles, labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gtWWUyOt4O_g"
   },
   "source": [
    "First, we plot the representations from the ten dimensional output layer, reduced down to two dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 592
    },
    "id": "xQDRASzrX1mV",
    "outputId": "b2247b66-b715-447d-c709-3fc39fecaaeb"
   },
   "outputs": [],
   "source": [
    "output_pca_data = get_pca(outputs)\n",
    "plot_representations(output_pca_data, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xwscI3sn4O_j"
   },
   "source": [
    "Next, we'll plot the outputs of the second hidden layer. \n",
    "\n",
    "The clusters seem similar to the one above. In fact if we rotated the below image anti-clockwise it wouldn't be too far off the PCA of the output representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 592
    },
    "id": "gE9HJK-EX70_",
    "outputId": "bcb1510c-04cc-455e-d13c-80e96d05c2ec"
   },
   "outputs": [],
   "source": [
    "intermediate_pca_data = get_pca(intermediates)\n",
    "plot_representations(intermediate_pca_data, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FDk5-M0_4O_m"
   },
   "source": [
    "An alternative to PCA is t-SNE (t-distributed stochastic neighbor embedding). \n",
    "\n",
    "This is commonly thought of as being \"better\" than PCA, although it can be [misinterpreted](https://distill.pub/2016/misread-tsne/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vw7O01SdkKsh"
   },
   "outputs": [],
   "source": [
    "def get_tsne(data, n_components=2, n_images=None):\n",
    "    if n_images is not None:\n",
    "        data = data[:n_images]\n",
    "    tsne = manifold.TSNE(n_components=n_components, random_state=0)\n",
    "    tsne_data = tsne.fit_transform(data)\n",
    "    return tsne_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-BJEuBfP4O_o"
   },
   "source": [
    "t-SNE is very slow, so we only compute it on a subset of the representations.\n",
    "\n",
    "The classes look very well separated, and it is possible to use [k-NN](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm) on this representation to achieve decent accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 592
    },
    "id": "RR3NPjJJklBa",
    "outputId": "e592cd16-3332-4c4a-aec1-b0eab5b9f598"
   },
   "outputs": [],
   "source": [
    "N_IMAGES = 5_000\n",
    "\n",
    "output_tsne_data = get_tsne(outputs, n_images=N_IMAGES)\n",
    "plot_representations(output_tsne_data, labels, n_images=N_IMAGES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "meihOEmK4O_r"
   },
   "source": [
    "We plot the intermediate representations on the same subset.\n",
    "\n",
    "Again, the classes look well separated, though less so than the output representations. This is because these representations are intermediate features that the neural network has extracted and will use them in further layers to weigh up the evidence of what digit is in the image. Hence, in theory, the classes should become more separated the closer we are to the output layer, which is exactly what we see here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 592
    },
    "id": "UCh-XJWclDfu",
    "outputId": "92e9559b-3964-45bc-ac9b-3f83c16fc1dc"
   },
   "outputs": [],
   "source": [
    "intermediate_tsne_data = get_tsne(intermediates, n_images=N_IMAGES)\n",
    "plot_representations(intermediate_tsne_data, labels, n_images=N_IMAGES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FqMOGh5u4O_u"
   },
   "source": [
    "Another experiment we can do is try and generate fake digits. \n",
    "\n",
    "The function below will repeatedly generate random noise and feed it through the model and find the most confidently generated digit for the desired class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4YG_Qc6do93Z"
   },
   "outputs": [],
   "source": [
    "def imagine_digit(model, digit, device, n_iterations=50_000):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    best_prob = 0\n",
    "    best_image = None\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for _ in trange(n_iterations):\n",
    "\n",
    "            x = torch.randn(32, 28, 28).to(device)\n",
    "\n",
    "            y_pred, _ = model(x)\n",
    "\n",
    "            preds = F.softmax(y_pred, dim=-1)\n",
    "\n",
    "            _best_prob, index = torch.max(preds[:, digit], dim=0)\n",
    "\n",
    "            if _best_prob > best_prob:\n",
    "                best_prob = _best_prob\n",
    "                best_image = x[index]\n",
    "\n",
    "    return best_image, best_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vokYX2Iq4O_z"
   },
   "source": [
    "Let's try and generate a perfect three."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f4Uh0BR-pAY5"
   },
   "outputs": [],
   "source": [
    "DIGIT = 3\n",
    "\n",
    "best_image, best_prob = imagine_digit(model, DIGIT, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0yhYVep94O_1"
   },
   "source": [
    "Looking at the best probability achieved, we have a digit that the model is 100% confident is a three. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "yUuvBXsU3lK1",
    "outputId": "6cd4d13b-7ea3-47fe-a71b-22d8af853e1d"
   },
   "outputs": [],
   "source": [
    "print(f'Best image probability: {best_prob.item()*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gvtjPCAE4O_3"
   },
   "source": [
    "Unfortunately, the imagined perfect three just looks like random noise.\n",
    "\n",
    "As mentioned before, the model has only been trained to be incredibly confident with its predictions, so when faced with random noise will try and classify it as something. \n",
    "\n",
    "It is also possible that the model is *overfitting* on the training set - that there is a common pattern in handwritten threes within the training set, but it's not the pattern we want our model to learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "0-0u1HGhpNrJ",
    "outputId": "568c9af6-4e70-40e9-8bb9-101a90db8170"
   },
   "outputs": [],
   "source": [
    "plt.imshow(best_image.cpu().numpy(), cmap='bone')\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8rpH_wa04O_6"
   },
   "source": [
    "Finally, we can plot the weights in the first layer of our model. \n",
    "\n",
    "The hope is that there's maybe one neuron in this first layer that's learned to look for certain patterns in the input and thus has high weight values indicating this pattern. If we then plot these weights, we should see these patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SMLbeLze0o8E"
   },
   "outputs": [],
   "source": [
    "def plot_weights(weights, n_weights):\n",
    "\n",
    "    rows = int(np.sqrt(n_weights))\n",
    "    cols = int(np.sqrt(n_weights))\n",
    "\n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "    for i in range(rows*cols):\n",
    "        ax = fig.add_subplot(rows, cols, i+1)\n",
    "        ax.imshow(weights[i].view(28, 28).cpu().numpy(), cmap='bone')\n",
    "        ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Pvv1B104O__"
   },
   "source": [
    "Looking at these weights we see a few of them look like random noise but some of them do have weird patterns within them. These patterns show \"ghostly\" image looking shapes, but are clearly not images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 575
    },
    "id": "yqzZus6a24_c",
    "outputId": "6140a7ab-56be-409c-c13a-d90a207e161b"
   },
   "outputs": [],
   "source": [
    "N_WEIGHTS = 25\n",
    "\n",
    "weights = model.input_fc.weight.data\n",
    "\n",
    "plot_weights(weights, N_WEIGHTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pfZg0Y2o4PAC"
   },
   "source": [
    "### Conclusions\n",
    "\n",
    "In this notebook we have shown: \n",
    "- loading Torchvision datasets\n",
    "- loading transforms to augment and normalize our data\n",
    "- defining a MLP\n",
    "- training a model to achieve >97% accuracy\n",
    "- viewing our model's mistakes\n",
    "- visualizing our data in lower dimensions with PCA and t-SNE\n",
    "- generating fake digits\n",
    "- viewing the learned weights of our model\n",
    "\n",
    "In the next notebook we'll implement a convolutional neural network (CNN) and evaluate it on the MNIST dataset."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "1 - Multilayer Perceptron.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
